{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doit_Ch07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnzcF8l8ud5q7joFAgSSvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owl-d/Basic_DeepLearning/blob/main/Doit_Ch07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4YVJT4Z12t_"
      },
      "source": [
        "# 07 다중 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbIY6c_r1-F1"
      },
      "source": [
        "***07-1 다중 분류하는 다층 신경망***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZXg3Q7D10O_"
      },
      "source": [
        "#06장에서 다룬 class 모음\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class SingleLayer:\n",
        "\n",
        "  def __init__(self, learning_rate=0.1, l1=0, l2=0):\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "    self.losses = []\n",
        "    self.val_losses = []\n",
        "    self.w_history = []\n",
        "    self.lr = learning_rate\n",
        "    self.l1 = l1\n",
        "    self.l2 = l2\n",
        "\n",
        "  def forpass(self, x): #정방향 계산\n",
        "    z = np.dot(x, self.w) + self.b\n",
        "    return z\n",
        "\n",
        "  def backprop(self, x, err): #역방향 계산\n",
        "    m = len(x)                    #샘플의 개수\n",
        "    w_grad = np.dot(x.T, err) / m #가중치에 대한 평균 그레디언트\n",
        "    b_grad = np.sum(err) / m      #절편에 대한 평균 그레디언트\n",
        "    return w_grad, b_grad\n",
        "\n",
        "  def activation(self, z):  #활성화 함수 메서드\n",
        "    z = np.clip(z, -100, None)\n",
        "    a = 1 / (1 + np.exp(-z))  #시그모이드 계산\n",
        "    return a\n",
        "\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):  #forpass(), backprop() 메서드에서 전체 샘플 한 번에 계산하므로 각 샘플에 대한 두 번쨰 for문 사라짐\n",
        "    y = y.reshape(-1, 1)  #target을 열 벡터로 바꾼다.\n",
        "    y_val = y_val.reshape(-1, 1)\n",
        "    m = len(x)            #샘플 개수\n",
        "    self.w = np.ones((x.shape[1], 1))  #가중치 초기화\n",
        "    self.b = 0                    #절편 초기화\n",
        "    self.w_history.append(self.w.copy()) #가중치 기록\n",
        "    for i in range(epochs):\n",
        "      z = self.forpass(x)   #정방향 계산\n",
        "      a = self.activation(z)   #활성화 함수 적용\n",
        "      err = -(y - a)        #오차 계산\n",
        "      w_grad, b_grad = self.backprop(x, err)  #역방향 계산\n",
        "      w_grad += (self.l1 * np.sign(self.w) + self.l2 * self.w) / m #L1규제와 L2규제 하나의 식으로 작성\n",
        "      self.w -= self.lr * w_grad\n",
        "      self.b -= self.lr * b_grad\n",
        "      self.w_history.append(self.w.copy())\n",
        "      a = np.clip(a, 1e-10, 1-1e-10)  #안전한 로그 계산 위해 클리핑 한 후 손실 누적\n",
        "      \n",
        "      loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a)))\n",
        "      self.losses.append((loss + self.reg_loss()) / m) #로그 손실과 규제 손실 더해 리스트에 추가\n",
        "\n",
        "      self.update_val_loss(x_val, y_val) #검증 세트에 대한 손실 계산\n",
        "\n",
        "  def predict(self, x):\n",
        "    z = self.forpass(x)  #정방향 계산\n",
        "    return z > 0         #계단 함수 적용(sigmoid 함수 적용하지 않아도 z의 값으로 알 수 있음)\n",
        "\n",
        "  def score(self, x, y):  #모델의 정확도\n",
        "    return np.mean(self.predict(x)==y.reshape(-1, 1)) #예측과 타깃 열 벡터 비교해 True의 비율 반환\n",
        "\n",
        "  def reg_loss(self): #가중치에 규제 적용\n",
        "    return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)\n",
        "\n",
        "  def update_val_loss(self, x_val, y_val): #검증 세트 손실 계산\n",
        "    z = self.forpass(x_val) #정방향 계산\n",
        "    a = self.activation(z)     #활성화 함수 적용\n",
        "    a = np.clip(a, 1e-10, 1-1e-10) #출력값 클리핑\n",
        "    val_loss = np.sum(-(y_val*np.log(a) + (1-y_val)*np.log(1-a))) #로지스틱 손실 함수의 값 계산\n",
        "    self.val_losses.append((val_loss + self.reg_loss()) / len(y_val)) #계산한 손실 함수 값 추가(L1, L2 규제 패널티 함수 포함)\n",
        "\n",
        "class DualLayer(SingleLayer):\n",
        "\n",
        "  def __init__(self, units=10, learning_rate=0.1, l1=0, l2=0):\n",
        "    self.units = units    #은닉층의 뉴런 개수\n",
        "    self.w1 = None\n",
        "    self.b1 = None\n",
        "    self.w2 = None\n",
        "    self.b2 = None\n",
        "    self.a1 = None\n",
        "    self.losses = []      #훈련 손실\n",
        "    self.val_losses = []  #검증 손실\n",
        "    self.lr = learning_rate\n",
        "    self.l1 = l1\n",
        "    self.l2 = l2\n",
        "\n",
        "  def forpass(self, x):\n",
        "    z1 = np.dot(x, self.w1) + self.b1       #첫 번째 층의 선형식 계산\n",
        "    self.a1 = self.activation(z1)           #활성화 함수 적용(SingleLayer클래스로부터 상속)\n",
        "    z2 = np.dot(self.a1, self.w2) + self.b2 #두 번째 층의 선형식 계산\n",
        "    return z2\n",
        "\n",
        "  def backprop(self, x, err):\n",
        "    m = len(x)      #샘플 개수\n",
        "    #출력층의 가중치, 절편에 대한 gradient 계산\n",
        "    w2_grad = np.dot(self.a1.T, err) / m\n",
        "    b2_grad = np.sum(err) / m\n",
        "    #sigmoid 함수까지 gradient 계산\n",
        "    err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1-self.a1)\n",
        "    #은닉층의 가중치, 절편에 대한 gradient 계산\n",
        "    w1_grad = np.dot(x.T, err_to_hidden) / m\n",
        "    b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
        "    return w1_grad, b1_grad, w2_grad, b2_grad\n",
        "\n",
        "  #SingleLayer에서는 fit() 메서드를 한 덩어리로 작성했지만, DualLayer 클래스의 fit() 메서드는 3개의 작은 메서드로 쪼갠다.\n",
        "  #1. 은닉층과 출력층의 가중치, 절편을 초기화\n",
        "  #2. 에포크마다 정방향 계산 수행해 오차 계산\n",
        "  #3. 오차 역전파해 가중치와 절편의 그레디언트 계산 및 업데이트\n",
        "  #4. 손실 계산하여 누적\n",
        "\n",
        "  def init_weights(self, n_features): #1\n",
        "    self.w1 = np.ones((n_features, self.units)) #(특성 개수, 은닉층의 크기)\n",
        "    self.b1 = np.zeros(self.units)              #은닉층의 크기\n",
        "    self.w2 = np.ones((self.units, 1))          #(은닉층의 크기, 1(=출력층의 크기))\n",
        "    self.b2 = 0\n",
        "\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None): #4\n",
        "    y = y.reshape(-1, 1)               #타깃을 열벡터로 바꾼다.\n",
        "    y_val = y_val.reshape(-1, 1)\n",
        "    m = len(y)                        #샘플 개수\n",
        "    self.init_weights(x.shape[1])     #은닉층, 출력층의 가중치 초기화\n",
        "    for i in range(epochs):\n",
        "      a = self.training(x, y, m)      #fit() 메서드의 for문 안에 있는 코드 중 일부를 training 메서드로 분리\n",
        "      a = np.clip(a, 1e-10, 1-1e-10)  #안전한 로그 계산 위해 클리핑\n",
        "      loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a))) #로그 손실\n",
        "      self.losses.append((loss + self.reg_loss()) / m)  #로그 손실과 규제 손실 더해 리스트에 추가\n",
        "      self.update_val_loss(x_val, y_val)                #검증 세트에 대한 손실 계산\n",
        "\n",
        "  def training(self, x, y, m): #2,3\n",
        "    z = self.forpass(x)       #정방향 계산 수행\n",
        "    a = self.activation(z)    #활성화 함수 적용\n",
        "    err = -(y - a)            #오차 계산\n",
        "    w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)      #오차 역전파 해 그레디언트 계산\n",
        "    w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
        "    w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m #그레디언트에서 패널티 항 미분값 뺀다\n",
        "    self.w1 -= self.lr * w1_grad\n",
        "    self.b1 -= self.lr * b1_grad  #은닉층 업데이트\n",
        "    self.w2 -= self.lr * w2_grad\n",
        "    self.b2 -= self.lr * b2_grad  #출력층 업데이트\n",
        "    return a  #출력층의 활성화 출력 a 반환\n",
        "\n",
        "  def reg_loss(self): #은닉층과 출력층의 가중치에 규제 적용\n",
        "    return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))\n",
        "\n",
        "class RandomInitNetwork(DualLayer):\n",
        "\n",
        "  def init_weights(self, n_features):\n",
        "    np.random.seed(42)\n",
        "    self.w1 = np.random.normal(0, 1, (n_features, self.units)) #평균, 분산, (특성 개수, 은닉층의 크기)\n",
        "    self.b1 = np.zeros(self.units)                             #은닉층의 크기\n",
        "    self.w2 = np.random.normal(0, 1, (self.units, 1))          #평균, 분산, (은닉층의 크기, 1)\n",
        "    self.b2 = 0\n",
        "\n",
        "class MinibatchNetwork(RandomInitNetwork):\n",
        "\n",
        "  def __init__(self, units=10, batch_size=32, learning_rate=0.1, l1=0, l2=0):\n",
        "    super().__init__(units, learning_rate, l1, l2)\n",
        "    self.batch_size = batch_size  #배치 크기\n",
        "\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None): #epoch 순회하는 for문 안에 미니 배치 순회하는 for문이 추가된다.\n",
        "    y_val = y_val.reshape(-1, 1)\n",
        "    self.init_weights(x.shape[1]) #은닉층과 출력층의 가중치 초기화\n",
        "    np.random.seed(42)\n",
        "    for i in range(epochs):\n",
        "      loss = 0    #손실 초기화\n",
        "      for x_batch, y_batch in self.gen_batch(x, y): #미니배치 순회\n",
        "        y_batch = y_batch.reshape(-1, 1)    #타겟을 열 벡터로 바꾼다.\n",
        "        m = len(x_batch)\n",
        "        a = self.training(x_batch, y_batch, m)\n",
        "        a = np.clip(a, 1e-10, 1-1e-10)\n",
        "        loss += np.sum(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a))) #매 미니배치마다 손실 누적\n",
        "      self.losses.append((loss + self.reg_loss()) / len(x))            #로그 손실과 규제 손실 더해 리스트에 추가\n",
        "      self.update_val_loss(x_val, y_val)\n",
        "\n",
        "  def gen_batch(self, x, y): #미니 배치 만들어 반환\n",
        "    length = len(x)\n",
        "    bins = length // self.batch_size  #미니 배치 횟수\n",
        "    if length % self.batch_size:\n",
        "      bins += 1                       #나누어 떨어지지 않을 때\n",
        "    indexes = np.random.permutation(np.arange(len(x)))  #인덱스를 섞는다\n",
        "    x = x[indexes]\n",
        "    y = y[indexes]\n",
        "    for i in range(bins):\n",
        "      start = self.batch_size * i\n",
        "      end = self.batch_size * (i + 1)\n",
        "      yield x[start:end], y[start:end]  #batch_size만큼 슬라이싱하여 반환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF67D1CkCULH"
      },
      "source": [
        "#다중 분류의 경사 하강법 알고리즘은 이진 분류의 경사 하강법 알고리즘과 원리는 같고 소프트맥스 함수가 추가된 점만 다르다.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MultiClassNetwork:\n",
        "    \n",
        "    def __init__(self, units=10, batch_size=32, learning_rate=0.1, l1=0, l2=0):\n",
        "        self.units = units         # 은닉층의 뉴런 개수\n",
        "        self.batch_size = batch_size     # 배치 크기\n",
        "        self.w1 = None             # 은닉층의 가중치\n",
        "        self.b1 = None             # 은닉층의 절편\n",
        "        self.w2 = None             # 출력층의 가중치\n",
        "        self.b2 = None             # 출력층의 절편\n",
        "        self.a1 = None             # 은닉층의 활성화 출력\n",
        "        self.losses = []           # 훈련 손실\n",
        "        self.val_losses = []       # 검증 손실\n",
        "        self.lr = learning_rate    # 학습률\n",
        "        self.l1 = l1               # L1 손실 하이퍼파라미터\n",
        "        self.l2 = l2               # L2 손실 하이퍼파라미터\n",
        "\n",
        "    def forpass(self, x):\n",
        "        z1 = np.dot(x, self.w1) + self.b1        # 첫 번째 층의 선형 식을 계산합니다\n",
        "        self.a1 = self.sigmoid(z1)               # 활성화 함수를 적용합니다\n",
        "        z2 = np.dot(self.a1, self.w2) + self.b2  # 두 번째 층의 선형 식을 계산합니다.\n",
        "        return z2\n",
        "\n",
        "    def backprop(self, x, err):\n",
        "        m = len(x)       # 샘플 개수\n",
        "        # 출력층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
        "        w2_grad = np.dot(self.a1.T, err) / m\n",
        "        b2_grad = np.sum(err) / m\n",
        "        # 시그모이드 함수까지 그래디언트를 계산합니다.\n",
        "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
        "        # 은닉층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
        "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
        "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
        "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
        "    \n",
        "    def sigmoid(self, z):\n",
        "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
        "        a = 1 / (1 + np.exp(-z))              # 시그모이드 계산\n",
        "        return a\n",
        "    \n",
        "    def softmax(self, z):\n",
        "        # 소프트맥스 함수\n",
        "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
        "        exp_z = np.exp(z)\n",
        "        return exp_z / np.sum(exp_z, axis=1).reshape(-1, 1)\n",
        " \n",
        "    def init_weights(self, n_features, n_classes):\n",
        "        self.w1 = np.random.normal(0, 1, \n",
        "                                   (n_features, self.units))  # (특성 개수, 은닉층의 크기)\n",
        "        self.b1 = np.zeros(self.units)                        # 은닉층의 크기\n",
        "        self.w2 = np.random.normal(0, 1, \n",
        "                                   (self.units, n_classes))   # (은닉층의 크기, 클래스 개수)\n",
        "        self.b2 = np.zeros(n_classes)\n",
        "        \n",
        "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "        np.random.seed(42)\n",
        "        self.init_weights(x.shape[1], y.shape[1])    # 은닉층과 출력층의 가중치를 초기화합니다.\n",
        "        # epochs만큼 반복합니다.\n",
        "        for i in range(epochs):\n",
        "            loss = 0\n",
        "            print('.', end='')\n",
        "            # 제너레이터 함수에서 반환한 미니배치를 순환합니다.\n",
        "            for x_batch, y_batch in self.gen_batch(x, y):\n",
        "                a = self.training(x_batch, y_batch)\n",
        "                # 안전한 로그 계산을 위해 클리핑합니다.\n",
        "                a = np.clip(a, 1e-10, 1-1e-10)\n",
        "                # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "                loss += np.sum(-y_batch*np.log(a))\n",
        "            self.losses.append((loss + self.reg_loss()) / len(x))\n",
        "            # 검증 세트에 대한 손실을 계산합니다.\n",
        "            self.update_val_loss(x_val, y_val)\n",
        "\n",
        "    # 미니배치 제너레이터 함수\n",
        "    def gen_batch(self, x, y): #미니 배치 만들어 반환\n",
        "        length = len(x)\n",
        "        bins = length // self.batch_size # 미니배치 횟수\n",
        "        if length % self.batch_size:\n",
        "            bins += 1                    # 나누어 떨어지지 않을 때\n",
        "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
        "        x = x[indexes]\n",
        "        y = y[indexes]\n",
        "        for i in range(bins):\n",
        "            start = self.batch_size * i\n",
        "            end = self.batch_size * (i + 1)\n",
        "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다.\n",
        "            \n",
        "    def training(self, x, y):\n",
        "        m = len(x)                # 샘플 개수를 저장합니다.\n",
        "        z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
        "        a = self.softmax(z)       # 활성화 함수를 적용합니다.\n",
        "        err = -(y - a)            # 오차를 계산합니다.\n",
        "        # 오차를 역전파하여 그래디언트를 계산합니다.\n",
        "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
        "        # 그래디언트에서 페널티 항의 미분 값을 뺍니다\n",
        "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
        "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
        "        # 은닉층의 가중치와 절편을 업데이트합니다.\n",
        "        self.w1 -= self.lr * w1_grad\n",
        "        self.b1 -= self.lr * b1_grad\n",
        "        # 출력층의 가중치와 절편을 업데이트합니다.\n",
        "        self.w2 -= self.lr * w2_grad\n",
        "        self.b2 -= self.lr * b2_grad\n",
        "        return a #출력층의 활성화 출력 a 반환\n",
        "\n",
        "    def predict(self, x): #정방향 계산에서 얻은 출력 중 가장 큰 값의 인덱스를 구한다. 이 값이 예측 클래스가 된다.\n",
        "        z = self.forpass(x)          # 정방향 계산을 수행합니다.\n",
        "        return np.argmax(z, axis=1)  # 가장 큰 값의 인덱스를 반환합니다. #이진 분류에서와 마찬가지로 소프트맥스 거치지 않아도 z값만으로 클래스 예측 가능\n",
        "    \n",
        "    def score(self, x, y): #모델의 정확도 #predict() 매서드의 결과와 타깃 y(배열 y의 행을 따라 가장 큰 값의 인덱스 구하여) 비교\n",
        "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
        "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
        "\n",
        "    def reg_loss(self): #은닉층과 출력층의 가중치에 규제 적용\n",
        "        # 은닉층과 출력층의 가중치에 규제를 적용합니다.\n",
        "        return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\n",
        "               self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))\n",
        "\n",
        "    def update_val_loss(self, x_val, y_val): #검증 세트 손실 계산\n",
        "        z = self.forpass(x_val)            # 정방향 계산을 수행합니다.\n",
        "        a = self.softmax(z)                # 활성화 함수를 적용합니다.\n",
        "        a = np.clip(a, 1e-10, 1-1e-10)     # 출력 값을 클리핑합니다.\n",
        "        # 크로스 엔트로피 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "        val_loss = np.sum(-y_val*np.log(a))\n",
        "        self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gorX-5ocCFyK"
      },
      "source": [
        "Fashion MNIST 데이터 세트 이용해 의류 이미지 분류하기(흑백)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFfU8xu2Bisb",
        "outputId": "8ebcf532-87a7-4634-a260-9cf35f4b7c1d"
      },
      "source": [
        "#1. 텐서플로 최신 버전 설치\n",
        "!pip install tensorflow_gpu==2.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_gpu==2.0.0\n",
            "  Downloading tensorflow_gpu-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (380.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8 MB 38 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (0.8.1)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (0.36.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==2.0.0) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.32.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (57.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (0.4.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow_gpu==2.0.0) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.5.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=6b821d62048c58243197cc0757d511e4b69dde73eb74b13e6c86bf9d5cf040fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires gast==0.4.0, but you have gast 0.2.2 which is incompatible.\n",
            "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.0.2 which is incompatible.\n",
            "tensorflow 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.0.1 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_NI7vaKsCNID",
        "outputId": "b82ea9c4-0d5d-402b-a90f-04bb4f28ff2f"
      },
      "source": [
        "#2. 텐서플로 버전 확인하기\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq63KK61CjIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73e6601-b505-44ef-b566-e4c3024c2354"
      },
      "source": [
        "#3. 패션 MNIST 데이터 세트 불러오기\n",
        "\n",
        "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84iE7m0HDD0S",
        "outputId": "16cd86f2-d037-446b-a2dd-d00a8f9808dc"
      },
      "source": [
        "#4. 훈련 세트의 크기 확인하기\n",
        "\n",
        "print(x_train_all.shape, y_train_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "rSM0D4m_EhyJ",
        "outputId": "4aa4749d-b229-402a-ed63-a57643ed2736"
      },
      "source": [
        "#5. imshow() 함수로 샘플 이미지 확인하기\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train_all[0], cmap='gray') #0번쨰 요소 확인\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPY2-X60FHdK",
        "outputId": "508358b2-562c-4a51-a323-3689d36b67ba"
      },
      "source": [
        "#6. 타깃의 내용과 의미 확인하기\n",
        "\n",
        "print(y_train_all[:10]) #가장 앞에 있는 데이터 10개의 target의 class label 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 3 0 2 7 2 5 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHkKbDCeGB4G",
        "outputId": "45c549fd-bdc7-4d4f-cd4c-d6b7c04e1ba1"
      },
      "source": [
        "class_names = ['티셔츠/윗도리', '바지', '스웨터', '드레스', '코트', '샌들', '셔츠', '스니커즈', '가방', '앵클부츠']\n",
        "\n",
        "print(class_names[y_train_all[0]]) #첫 번째 샘플의 클래스"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "앵클부츠\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWHG7-dDGS7P",
        "outputId": "e325fe11-7366-4bae-d683-bf419c77d8e5"
      },
      "source": [
        "#7. 타깃 분포 확인하기\n",
        "\n",
        "np.bincount(y_train_all) #각 클래스 당 샘플이 몇 개씩 있는지 확인\n",
        "\n",
        "#label 당 6000개의 데이터가 존재한다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbLJ5NrqG61w",
        "outputId": "4ba102ca-5601-46d9-a748-8b1bfb98a22b"
      },
      "source": [
        "#8. 훈련 세트와 검증 세트 고르게 나누기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)\n",
        "\n",
        "#훈련, 검증 세트의 레이블이 잘 나누어졌는지 확인 -> 80:20의 비율로 나누어짐\n",
        "print(np.bincount(y_train))\n",
        "print(np.bincount(y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]\n",
            "[1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh5qtez_L8F6"
      },
      "source": [
        "#9. 입력 데이터 정규화하기 : '표준화'했다고 말할 수 없지만 잘 작동\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_val = x_val / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsWEGVliMPd1",
        "outputId": "ba8b37cc-021f-4940-8d2c-62dfd0a73760"
      },
      "source": [
        "#10. 훈련 세트와 검증 세트의 차원 변경하기\n",
        "#기존 28X28 크기의 2차원 배열이나, 네트워크에는 1차원 배열의 샘플을 입력해야 하므로 이어붙인다.\n",
        "\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_val = x_val.reshape(-1, 784)\n",
        "\n",
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784) (12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX7r5ZZPUG-6"
      },
      "source": [
        "타깃 데이터 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj_n2r37UNAW",
        "outputId": "1d291372-fe25-4117-db0b-7dd0e35b7f3c"
      },
      "source": [
        "#1. 타깃을 원-핫 인코딩으로 변환\n",
        "#타깃값들은 0~9 사이의 정수값 중 하나로 10개의 출력 뉴런에 대응되지 않는다. 따라서 이에 대응하는 배열로 변환한다.\n",
        "#타깃의 정수값에 해당하는 원소는 1, 나머지 원소는 모두 0으로 하여 10개의 원소를 가진 배열로 만든다.\n",
        "\n",
        "#아래는 to_categorical을 사용해 원-핫 인코딩을 하는 예시\n",
        "print(tf.keras.utils.to_categorical([0, 1, 3]))\n",
        "\n",
        "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
        "y_val_encoded = tf.keras.utils.to_categorical(y_val)\n",
        "print(y_train_encoded.shape, y_val_encoded.shape) #변환된 원-핫 인코딩 배열의 크기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "(48000, 10) (12000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWlSl5Lr_taK",
        "outputId": "d52c9cc3-e156-4a56-f0d7-118c6346ef5c"
      },
      "source": [
        "#2. 만든 배열의 각 원소를 뉴런의 출력값과 비교하여, 가장 큰 출력값이 인덱스가 타깃과 동일한지 비교\n",
        "\n",
        "print(y_train[0], y_train_encoded[0]) #첫 번째 label 6 출력해보기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78MsKQ01XBya"
      },
      "source": [
        "MultiClassNetwork 클래스로 다중 분류 신경망 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEF2z8PXVLC_",
        "outputId": "401adbbe-3ca4-40a6-a508-8bb8a1ebaadf"
      },
      "source": [
        "#MultiClassNetwork 클래스로 다중 분류 신경망 훈련하기\n",
        "\n",
        "fc = MultiClassNetwork(units=100, batch_size=256)\n",
        "fc.fit(x_train, y_train_encoded, x_val=x_val, y_val=y_val_encoded, epochs=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "........................................"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "k977J7WXXLk8",
        "outputId": "c2cf6480-cad0-48a8-a401-07b7c0a46611"
      },
      "source": [
        "#훈련 손실, 검증 손실 그래프 확인하기\n",
        "\n",
        "plt.plot(fc.losses)\n",
        "plt.plot(fc.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteration')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()\n",
        "\n",
        "#손실 그래프가 초기에는 빠르게 감소하다가 완만하게 수렴"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpBXa5QFXlMm",
        "outputId": "30282bda-58c5-420d-b87f-8b46294955dc"
      },
      "source": [
        "#훈련 모델 점수 확인\n",
        "\n",
        "fc.score(x_val, y_val_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8150833333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyXNEhAf2DYH"
      },
      "source": [
        "***07-2 텐서플로와 케라스 이용해 신경망 만들기***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvG-GSb2drRQ"
      },
      "source": [
        "#간단한 신경망을 텐서플로로 구현 #왜 안 돼\n",
        "\n",
        "#훈련할 가중치 변수 선언\n",
        "w = tf.Variable(tf.zeros(shape=(1)))\n",
        "b = tf.Variable(tf.zeros(shape=(1)))\n",
        "\n",
        "#경사하강법 옵티마이저 설정\n",
        "optimizer = tf.optimizers.SGD(lr = 0.01)\n",
        "#epoch 만큼 훈련\n",
        "num_epochs = 10\n",
        "for step in range(num_epochs):\n",
        "\n",
        "  #자동 미분을 위해 연산 과정 기록\n",
        "  with tf.GradientTape() as tape:\n",
        "    z_net = w * x_train + b\n",
        "    z_net = tf.reshape(z_net, [-1])\n",
        "    sqr_errors = tf.square(y_train - z_net)\n",
        "    mean_cost = tf.reduce_mean(sqr_errors)\n",
        "  #손실 함수에 대한 가중치의 gradient 계산\n",
        "  grads = tape.gradient(mean_cost, [w, b])\n",
        "  #옵티마이저에 그레디언트 반영\n",
        "  optimizer.apply_gradients(zip(grads, [w, b]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU4t7f47iMp0",
        "outputId": "a2d9a63d-7e3b-45ba-db57-481a41fce390"
      },
      "source": [
        "#신경망을 케라스로 구현 : 간단하다.\n",
        "\n",
        "#신경망 모델 만든다.\n",
        "model = tf.keras.models.Sequential()\n",
        "#완전 연결층 추가\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "#옵티마이저, 손실 함수 지정\n",
        "model.compile(optimizer='sgd', loss='mse')\n",
        "#훈련 데이터 사용해 epoch 횟수만큼 훈련\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 1ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa4d3a7fb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbp84bnJjB9D"
      },
      "source": [
        "#Sequential 클래스 사용법 : 인공신경망 모델 만듦\n",
        "\n",
        "#1. Sequential 클래스의 객체를 생성할 때 Dense 클래스로 만든 층을 추가\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential([Dense(...), ...]) #신경망 모델에 추가할 층을 파이썬 리스트로 만들어 전달하면 Sequential 클래스의 객체가 만들어질 때 층이 추가된다.\n",
        "\n",
        "#2. 객체를 생성한 후 add() method 사용해 층을 추가\n",
        "dense = Dense(...)\n",
        "model.add(dense)\n",
        "\n",
        "#or Dense 클래스 객체 만들어 바로 전달도 가능\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(...))\n",
        "model.add(Dense(...))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4cR2aN2m4oC"
      },
      "source": [
        "#Dense 클래스 사용법 : fully connected layer 만듦\n",
        "\n",
        "Dense(unit=100, activation='sigmoid')\n",
        "#units : 뉴런의 개수(하이퍼파라미터)\n",
        "#activation : 활성화 함수 지정. 기본값은 'None'이므로 지정하지 않으면 활성화 함수 적용되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTBXuL7toQMW"
      },
      "source": [
        "케라스로 다중 분류 신경망 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9viaTfneoP0i"
      },
      "source": [
        "#1. 모델(Sequential 객체) 생성\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-q9lE4cpt_a"
      },
      "source": [
        "#2. 은닉층과 출력층을 모델에 추가\n",
        "model.add(Dense(100, activation='sigmoid', input_shape=(784,))) #은닉층의 유닛 개수는 100개, 활성화 함수는 sigmoid 함수,\n",
        "                                                #입력 데이터의 크기는 28X28=784, 입력 행렬의 첫번쨰 차원인 입력 데이터의\n",
        "                                                #개수는 신경망 구성에 불필요하므로 입력하지 않는다. \n",
        "model.add(Dense(10, activation='softmax'))                      #출력층의 유닛 개수는 10개, 활성화 함수는 softmax 함수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6n4WBbfqyRG"
      },
      "source": [
        "#3. 최적화 알고리즘과 손실 함수 지정하기\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#optimizer : 최적화 알고리즘. 'sgd'는 기본 경사 하강법이고, learning rate의 기본값은 0.01이다.\n",
        "#loss : 손실함수. 'categorical_crossentropy'는 크로스 엔트로피 손실 함수이다.\n",
        "#metrics : 훈련 과정 기록으로 정확도 남기기 위해 추가. 지정하지 않으면 기본값으로 손실값(loss)가 기록된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byio7Lo4rp1l",
        "outputId": "2c3ae30f-d70c-4846-c897-d521aae89058"
      },
      "source": [
        "#4. 모델 훈련하기\n",
        "#검증 세트에 대한 손실과 정확도 계산 위해 validation_data 매개변수에 검증 세트를 튜플로 전달\n",
        "#fit() mothod는 훈련 세트와 검증 세트에서 측정한 값들을 History 클래스 객체에 담아 반환\n",
        "\n",
        "history = model.fit(x_train, y_train_encoded, epochs=40, validation_data=(x_val, y_val_encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 1.3973 - accuracy: 0.6417 - val_loss: 0.9689 - val_accuracy: 0.7369\n",
            "Epoch 2/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.8472 - accuracy: 0.7449 - val_loss: 0.7541 - val_accuracy: 0.7608\n",
            "Epoch 3/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7132 - accuracy: 0.7634 - val_loss: 0.6649 - val_accuracy: 0.7805\n",
            "Epoch 4/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6475 - accuracy: 0.7791 - val_loss: 0.6147 - val_accuracy: 0.7867\n",
            "Epoch 5/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6057 - accuracy: 0.7926 - val_loss: 0.5792 - val_accuracy: 0.7977\n",
            "Epoch 6/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5753 - accuracy: 0.8031 - val_loss: 0.5514 - val_accuracy: 0.8093\n",
            "Epoch 7/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5523 - accuracy: 0.8100 - val_loss: 0.5315 - val_accuracy: 0.8163\n",
            "Epoch 8/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5344 - accuracy: 0.8169 - val_loss: 0.5150 - val_accuracy: 0.8194\n",
            "Epoch 9/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5196 - accuracy: 0.8202 - val_loss: 0.5017 - val_accuracy: 0.8246\n",
            "Epoch 10/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5074 - accuracy: 0.8246 - val_loss: 0.4912 - val_accuracy: 0.8282\n",
            "Epoch 11/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4970 - accuracy: 0.8273 - val_loss: 0.4829 - val_accuracy: 0.8299\n",
            "Epoch 12/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4880 - accuracy: 0.8306 - val_loss: 0.4742 - val_accuracy: 0.8320\n",
            "Epoch 13/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4803 - accuracy: 0.8329 - val_loss: 0.4669 - val_accuracy: 0.8357\n",
            "Epoch 14/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4733 - accuracy: 0.8357 - val_loss: 0.4608 - val_accuracy: 0.8368\n",
            "Epoch 15/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4669 - accuracy: 0.8373 - val_loss: 0.4529 - val_accuracy: 0.8417\n",
            "Epoch 16/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4612 - accuracy: 0.8393 - val_loss: 0.4469 - val_accuracy: 0.8428\n",
            "Epoch 17/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4557 - accuracy: 0.8405 - val_loss: 0.4437 - val_accuracy: 0.8425\n",
            "Epoch 18/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4509 - accuracy: 0.8421 - val_loss: 0.4390 - val_accuracy: 0.8432\n",
            "Epoch 19/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4465 - accuracy: 0.8438 - val_loss: 0.4345 - val_accuracy: 0.8449\n",
            "Epoch 20/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4421 - accuracy: 0.8454 - val_loss: 0.4302 - val_accuracy: 0.8479\n",
            "Epoch 21/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4384 - accuracy: 0.8468 - val_loss: 0.4283 - val_accuracy: 0.8498\n",
            "Epoch 22/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4346 - accuracy: 0.8469 - val_loss: 0.4246 - val_accuracy: 0.8488\n",
            "Epoch 23/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4312 - accuracy: 0.8487 - val_loss: 0.4206 - val_accuracy: 0.8501\n",
            "Epoch 24/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4276 - accuracy: 0.8493 - val_loss: 0.4204 - val_accuracy: 0.8512\n",
            "Epoch 25/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4246 - accuracy: 0.8505 - val_loss: 0.4163 - val_accuracy: 0.8531\n",
            "Epoch 26/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4217 - accuracy: 0.8516 - val_loss: 0.4121 - val_accuracy: 0.8545\n",
            "Epoch 27/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4186 - accuracy: 0.8538 - val_loss: 0.4119 - val_accuracy: 0.8544\n",
            "Epoch 28/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4158 - accuracy: 0.8547 - val_loss: 0.4085 - val_accuracy: 0.8562\n",
            "Epoch 29/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4134 - accuracy: 0.8550 - val_loss: 0.4065 - val_accuracy: 0.8552\n",
            "Epoch 30/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4109 - accuracy: 0.8558 - val_loss: 0.4061 - val_accuracy: 0.8561\n",
            "Epoch 31/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4085 - accuracy: 0.8562 - val_loss: 0.4037 - val_accuracy: 0.8574\n",
            "Epoch 32/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4061 - accuracy: 0.8579 - val_loss: 0.4017 - val_accuracy: 0.8580\n",
            "Epoch 33/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4038 - accuracy: 0.8580 - val_loss: 0.3985 - val_accuracy: 0.8600\n",
            "Epoch 34/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4016 - accuracy: 0.8579 - val_loss: 0.3959 - val_accuracy: 0.8602\n",
            "Epoch 35/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3995 - accuracy: 0.8593 - val_loss: 0.3948 - val_accuracy: 0.8611\n",
            "Epoch 36/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3975 - accuracy: 0.8594 - val_loss: 0.3925 - val_accuracy: 0.8614\n",
            "Epoch 37/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3957 - accuracy: 0.8605 - val_loss: 0.3918 - val_accuracy: 0.8623\n",
            "Epoch 38/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3936 - accuracy: 0.8613 - val_loss: 0.3894 - val_accuracy: 0.8628\n",
            "Epoch 39/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3916 - accuracy: 0.8615 - val_loss: 0.3887 - val_accuracy: 0.8625\n",
            "Epoch 40/40\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3899 - accuracy: 0.8626 - val_loss: 0.3874 - val_accuracy: 0.8633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHYBY1ISsX7d",
        "outputId": "f2920343-d1a8-451f-892c-8bbae409070f"
      },
      "source": [
        "#5. 손실과 정확도 그래프 그리기\n",
        "#반환된 history dictionary의 키를 출력해보면 어떤 측정 지표들이 들어가 있는지 확인 가능\n",
        "print(history.history.keys())\n",
        "\n",
        "#차례대로 훈련 세트에서의 손실, 검증 세트에서의 손실, 훈련 세트의 정확도, 검증 세트의 정확도"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "6-prol85ssDD",
        "outputId": "1f487f71-2283-4a8f-ed00-f5deaf6415e2"
      },
      "source": [
        "#훈련 세트와 검증 세트의 손실 그래프 나타낸 그래프\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()\n",
        "\n",
        "#일정한 수준으로 감소"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "7EWrhp8BtRcS",
        "outputId": "d9d92ec8-2b0d-42a7-e5fe-bba01ddd09ba"
      },
      "source": [
        "#훈련 세트와 검증 세트의 정확도 나타낸 그래프\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy', 'val_accuracy'])\n",
        "plt.show()\n",
        "\n",
        "#점진적으로 증가하는 추세"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXzU9Z348dc7k/siIQnhCBBuQoBwRMTiQUUsta1nEd3qqq26teq22G1Lq63U7rZ2293+dGtttWrVqlixVWqtigU8Kig3AqLcEK4kkwSSkGSSzPv3x/ebMIEJhpBhJpn38/GYx3zvefPVzHu+n1NUFWOMMeZ4MeEOwBhjTGSyBGGMMSYoSxDGGGOCsgRhjDEmKEsQxhhjgooNdwBdJTs7W/Pz88MdhjHGdCurV68uV9WcYPt6TILIz89n1apV4Q7DGGO6FRHZ3d4+K2IyxhgTlCUIY4wxQVmCMMYYE5QlCGOMMUFZgjDGGBOUJQhjjDFBWYIwxhgTVI/pB2GMMd1OUwPUH4HGoxCbAHFJEJcMnrjgx/uOQm0ZHC2H2nJnubYMEjOg+KYuD88ShDHGdAVVaDgC1QfhyH6oPnDsvfog1B929tcfgYZqZ7nZF/xa4nESRVwSxCWigNaWE9N4NOjh2xLGMNwShDHGhJCq8+VdUwo1h6Dm4LHluiporHN+7TfVH1turANfrfOLvrH2xGsm9kJT+9GY0Iv62Czq0gZSnZbMEU2isjmR8qYEKn2x0NxAbHM9nuZ6Yv0NxDXXE9fYQLy/nma/n3ItxKu9KCcdr6bTnJRFXHouKZm5jBzYl+EhuB2WIIwxPVdzExzaCHvfh0ObnC/z5ganaKepwfkF31QPTT7wuYkhyK90jYmDpAw0NgniktBY5+WPS8eflIvGJlIbm0FFTBYH/JnsbcpgW306H9Ums/swHNpXT7DJO9MSY8lJTaB3SjxJ8R7iPTHEx8aQEOu8O8seUuI99M9IYlRmEv0zkhiQkURinCfkt88ShDGm56g/DHtXOglh7wooWX3sV31yFiSkO2X9nniITXSWEzOc5fhk/Cm5HPb0Zn9TGjvrU/moJpkNVQmsKxeqvc0dDiM+NoYBGUn0z0jkvBFJ9MtIok9aAjktr1Tn/Ux8yZ8OSxDGmMjm98ORfeDd5hTj1FVCfRV6tJLaI+XUVHlprKkgtt5LbuNeYlCaiWGXZwibYj/LxqRRbJACDkg2nkbB0yx4YpxXbIwQ477XNDSzo6yGhiZ/60fnpCUwPCeVyyem0ictofVYT4wQI+57jOARoXdKHP0znF/4WSnxiEgYb1rXsARhjOka1Qehchek9YX0Ae23xAlGFeqroGKnkwjKt9JcvhXKP0EqdhDTVHfCKXWawBFSOKwpHCGFxvj+LEs5n60JhexOHE1TbCpxHiE2JoZsj5AbIzT7Fb8qTc3uu19pdl+56bFMG5bF8D6pjMhNZXhOGr2ST+Hf0ANZgjDGnLr6I7B/LexfA/tWw741zq/8FhKDpvVHew2kKS0PX1oe9cn9OUoSDVX78R/eR0zNIeKPHiS5oZT0Ji8J2tB6erMKJZrDDu3HDp3uvvfjkGbSEJvOgL65jBqQTWH/dMb0T6coNy3ii2u6I0sQxkSzxnrwboWyj52Xd6uzTWIgJsZ5F4+77sHna0APbiK+ahuCU+vqjR/AtrhRbEy5hI98uaQ1ecnxl5JbWUpeVRkDZCv98JIqx2ppGzSOg5pJmfSmKnYoNYlTaUjqQ13yAGpS86lPzycpKZnkeA9p8bGck+DhovhYBmUlk5+Vgiem+xffdAeWIIyJBqpO8U/JKjj0IZR9AmVboGo3qFvmLjGQMRgS0pxt6qepqYk6XyMNvkZ8jU00Nvv5RPPY4L+K9TqMDf6hENOb3KRE+qQnkJ2agC/eQ0Wch6NxHg7Ge9gY5yHJ00zvZi9pMfWkZA2kd1Yu2WkJDE6wr6BIFtL/OiIyC3gA8AC/V9X7j9s/CHgSyHCPmaeqr4pIPvAR8LF76ApV/XooYzWmR2modop9SlY6SaFkpdP7FiAmDrJHQL8iGD8HckZCzmiaMoawr0ZZs6eS93dUsGKHl11ep8lnWkIsZw3pzVn5vcnPSmZ6egJXpyWeYkucULTUN6EUsgQhIh7gIWAmUAKsFJFFqro54LB7gD+p6sMiMgZ4Fch3921X1Qmhis+Ybq+xDqr2QtUeOLzHea/a4xQVlW4+9mSQPRJGfg4dUExl7yJ2yED2HvZRUlHHXu9R9m6tY2/lIQ4c3k2z3ykGSk+MZcqQLK6bOpizh2Qxpn+6FetEoVA+QUwBtqnqDgARWQBcBgQmCAXS3eVewP4QxmNMeB2tcH7V718LsfFOS59eec4rtS94gvw5Hq0A73ao2A4VO5zlyp1OIqgta3tsTBzaawBNvYZQVnQnOxLGsE6HsaXKw849texaU0ut7yBwsPWUnLQEBmYmMXlwJgMzkxnYO4mxA3oxuq8lBBPaBDEA2BuwXgKcfdwx84E3ROROIAW4KGDfEBFZCxwB7lHVd47/ABG5FbgVYNCgQV0XuTGnq7nJ+RUfWMTj3dr+8RIDaf2cpJHaxxnDp2KH0/TTpRJDbWI/yuL6UxZ/NgcT+1CiOexuzmKHrzc7G9I4XOqn8cCxyuAYKSUvM5kh2SmtxUODs1IY2DuJvMxka/ljTircNUTXAn9Q1f8RkXOAp0VkLHAAGKSqXhGZDLwkIoWqeiTwZFV9BHgEoLi4OEhHdmPOoLoq2PI32PRn2L08oAdvNgycAhOuhbyzoP9Ep9L4yD44vA8O7z22fKQE9W7jaEIfDuZ+jq1NuaytzeRtbzrbG7Px1cURHxtDZnIc6YlxpCXGkp4WR7/EOEYlxZKeGEfvlHiGZKeQn53CwMxk4mNtVH/TOaFMEPuAgQHree62QF8DZgGo6nIRSQSyVbUUaHC3rxaR7cBIYFUI4zXm1DXUwCevwcY/w7bFztg+GYNg4lcgbwrNA4op0Ry2ltaytbSGrSur2V66npqGJpr9SpM/hqbmQTT5B9Ls99PkVxoa/fianfqDpDgPYwekc86UDP4trxfj8noxJCuFGCv+MWdAKBPESmCEiAzBSQzXAP9y3DF7gBnAH0SkAEgEykQkB6hQ1WYRGQqMAHaEMFZjOq6hBnYshY0vwsevQVMdmtaP2qKb2JI1k/cb8p1ksKyG7WVbqG88Vu3WNz2R4X1SyctMJtZzbLgHT0wMce56fGwMI/ukMS6vF8NyUq0uwIRNyBKEqjaJyB3A6zhNWB9X1U0ich+wSlUXAd8GHhWRuTgV1jeqqorI+cB9ItII+IGvq2pFqGI1pl0NNXBwA+xfBwfWwf61aPlWBKU+vjcbMj7P3/QzvOwdSNV7zYAP+IT+vRIZkZvGZ4ZlMaJPGsNzUxneJ5X0xOgeusF0L6LBxqDthoqLi3XVKiuBinrNjU6ZftUeZ90dntmZfCXReW8ZxbP+sNNK6KgX6tz3oxXO8uF9cGBdazIAqIrN5iOGsqJ+ECv9I3nfX0BCfDyj+6Yxul86Be77qL5plghMtyEiq1W1ONi+cFdSG9M5VXuc1kGVuwJeO+FwybH2/53ULLFUxfTmIx3MysYr2aBD2egfgie9L4X90ynsn86/9k/nZ/3SGZiZbPUBpseyBGG6l9pyeOvnsOpx8Dc521JyIDMfBp7t9AzOzHcqimNi3Vm/6lpn//I31lFTc4SqIzXsr49n59EEPj4Sx8bKWA42pVClqRyVJPKzUyns34vC/ul8tX86Y/qlk5WaEM5/uTFnnCUI0z001sGKh+HdXznTO06+AYq/CplDICH1hMMran1sK61hV2UtO7217CqvZWd5Lbu8tdQ3HnvCyEqJZ3S/NIpGpjOnbxqj+6YzIjfV+gcYgyUIE+n8fvjwT/CPn8CREhj5eZj5Y8gZ1XpIs1/ZWlrN6t2VrN5dyZrdla1jCAHExgiDejudxaYNzyY/O4UhWSmM6ptGTpo9FRjTHksQJnLtWAZv/NBpRdRvAlzxWzT/XA4daeCjj0tZv7eK1bsrWbeniuoGp7gpOzWeSYMyuWbKIEb3TWNIdgoDMpKI9VhnMWNOlSUIE151VU7lcpvK5l3OzGJVu/GlDGB10f28EXMum9+oYcvBxRyuawQgRmBU33Qum9ifyYMzmTyoNwN7J/WIqR6NiQSWIMyZt28NrPw9fPyqM79wgOakLMpj+7HFl8+ypgt41nshDd54UuL3MapvGpeM60dBP6euoKBfGmnWnNSYkLEEYc6MxnrY/BJ88IgzRWVcCoy5DHLHcCAml2WHUli4M5bVB52ioqK8Xkwv7sOD/dMp6JtOXmaSNSc15gyzBGFCq2qv0yR1zZNOR7SsETR/7udsyP48S3fW8/cVB9laWgNA8eA07vlCX2aN7UteZnKYAzfGWIIwXcvvd6ay3LMctr0Jn7yGAtWDZvJO5uUsrBjGB3+vpNa3kRiBKUN6c/05hXyusC+56Ynhjt4YE8AShDk9TT44sB72vOcMcb13RWu9wtGEHN7qNYf/V3UeH3+cAcCwnDqunJTHZ4ZlMXVoFpkp8eGM3hhzEpYgTMf5/U6Lo/1r3YHr1jnDXTTVAaC9h7G/7wzeqBnC0/sGsKM+h7yYZD4zNovbhmVzzrAse0owphuxBGHad2Q/7H7vWDI4sAEaDjv7PAmQWwiTb+BArwn8qXQgT2+so3y/j+zUBK46dwBfnpzHiNy08P4bjDGdZgnCtOX3w/Z/wMrHYOvrzsB3nnjIHQvjrnI6rPWfSGnSEN7YUsHC1SWs21tFbMwRZhT0YfbkgVwwKoc465hmTLdnCcI4asth7dOw6gmo2u0MgHfuXCi4FPqMQT1xbC+r4Y3Nh1j8l0Os3fM2ACNzU7nnCwVcPnEA2TaYnTE9iiWIaKbqtDZa+Rh8tMiZLnPwuXDRvTD6SzTHxLFmTyWL39jO4s2H2FnuzLE8Pq8X3545kpmFuYzKTbOey8b0UJYgotX+tfDqd6HkA0jo5YyMWvxVyBmFr8nPi2tK+PWSbeyrqiPOI0wdmsVXzx3CRQV96NcrKdzRG2POAEsQ0abWC0vug9VPQko2fOF/oegaiE9xEsMHe1oTw4SBGXzv86OZPirHZkgzJgpZgogWzU2w+glY8p/QUA1Tb4Pp8yCxV9DE8F9XjOWCkTlWfGRMFLMEEQ12vwevfgcObYQh58Pn/xv6FFhiMMaclCWInqx0C7zzS/jwBUjPg9lPwpjL2HTgCC/+dTMvr9uHt9ZnicEYE5QliJ6m+hBsXAgbnneGwPAkwPnfoXzi7by8qYqFD77LRweOEO+J4aIxfbjmrEGcNyLbEoMx5gSWIHoCXy1s+ZuTFLYvcTq39ZtA88U/463483l2Uz3L3lxOk18pyuvFfZcV8qXx/W0cJGPMSVmC6M6OHIAlP4HNL4OvBnoNdDq3jZ9DWWI+dzy7hvd37qZPWgJfO3cIV03OY6QNfWGM6SBLEN3V7uXwwg1QfwTGfdlpqjroMxATw9o9ldz26LtU1fn476vGc+WkATYnszHmlFmC6G5Unek6X5sHGYPg+pcgd0zr7mff38P8RZvok57Ai7d9hsL+vcIYrDGmO7ME0Z001sErc2H9czByFlzxO0hy5lmob2xm/qJNLFi5l/NGZPN/104kI9nqGIwxnWcJoruo3A3PXwcHN8D078P534UYp9hof1Udtz2zhvV7q7j9s8O4a+YoPDZ/szHmNFmC6A62L4GFXwN/M1z7PIya1bpr+XYvdzy7hoYmP7+9bjKzxvYNY6DGmJ7EEkSk++cD8OZ8yB4F1zwDWcMAUFUee3cnP/v7FvKzkvnd9cUM75Ma3liNMT2KJYhItu45WPwjGHM5XPYQJDgJoLahie+9uIFXNhzgc4W5/HJ2EWk2mJ4xpotZgohUZR/D3+5y5me46jHwOP+pdpTV8PU/rmZbaQ3fmzWar18w1HpBG2NCwhJEJPIdhT/dAHHJcNXvW5PD4s2HuOv5dcR6hKe+ejbnjsgOc6DGmJ7MEkQk+vt3oGwLXPcipPej2a/8avEn/HrpNsYN6MXD100iLzM53FEaY3o4SxCRZt1zsPaPcP53YPgMKmt9fPP5dbz9SRlzigfy48sKSYzzhDtKY0wUsAQRSQLrHS6YR+mRer782+UcPFzPz64cx7VTBoU7QmNMFAnpAD0iMktEPhaRbSIyL8j+QSKyVETWisgGEbkkYN/33fM+FpHPhTLOiHBcvUO9X7j16dWUVTfw3K1TLTkYY864kD1BiIgHeAiYCZQAK0VkkapuDjjsHuBPqvqwiIwBXgXy3eVrgEKgP/CmiIxU1eZQxRt2AfUOmtaX7/9pPev2VvHb6yYzeXBmuKMzxkShUD5BTAG2qeoOVfUBC4DLjjtGgXR3uRew312+DFigqg2quhPY5l6vZ2qtd/gPGD6D3761g7+s3cd/XDzSekYbY8ImlAliALA3YL3E3RZoPnCdiJTgPD3ceQrnIiK3isgqEVlVVlbWVXGfWa31DtPggnks3nyI/359C18q6s/tnx0e7uiMMVEs3JMEXAv8QVXzgEuAp0WkwzGp6iOqWqyqxTk5OSELMmQaagLqHR5jS9lRvrVgLeMG9OIXXx5vHeCMMWEVylZM+4CBAet57rZAXwNmAajqchFJBLI7eG73pgovfwPKP4br/ow3pjc3P/lPUhNjefRfi60pqzEm7EL5BLESGCEiQ0QkHqfSedFxx+wBZgCISAGQCJS5x10jIgkiMgQYAXwQwljPvH8+4EwVetF8fIMv4LY/rqGsuoFHri8mNz0x3NEZY0zoniBUtUlE7gBeBzzA46q6SUTuA1ap6iLg28CjIjIXp8L6RlVVYJOI/AnYDDQBt/eoFkzbl8A/fgyFV6Dn3MkP/7yRD3ZV8OC1EykamBHu6IwxBgBxvo+7v+LiYl21alW4w/h0lbvgkemQ1g9ufpPHPyjlvlc2c+eFw/n2xaPCHZ0xJsqIyGpVLQ62L9yV1NHFdxQWXAfqhzl/ZEtFMz/7+0fMHJPL3ItGhjs6Y4xpwxLEmaIKf/0mHNoIVz1Gc+ZQvrdwA2mJcfz8qvHE2BShxpgIYwniTFnxMHz4J7jwbhgxkyf+uZP1JYeZf2khvVPiwx2dMcacwBLEmbDzHXjjHhj9RTj32+z21vLLNz7mooI+fGl8v3BHZ4wxQVmCCLWqvfDCjZA1HK74LSrCvBc/JC4mhp9cPtY6wxljIpYliFDa9S488Xlo9sE1z0BCGgtW7mX5Di/fv6SAfr2Swh2hMca0yxJEKDT5YPG98IcvgicO/vUlyB7BwcP1/PRvH3HO0CyunTLw069jjDFhZBMGdbWyj+HFm+HgBph0A3zup5CQiqpyz0sf0uj387Mrx1nRkjEm4lmC6CqqsPL3TmV0fApc8yyM/kLr7lc2HODNj0q5+5IC8rNTwhioMcZ0jCWIrlB9CF6+HbYthuEXwWW/gbTc1t0VtT7mL9pEUV4vbpqWH744jTHmFFiCOF37VsMzs8FXC5//BUy5BY4rPvrJK5s5XNfIM7ecTazHqn2MMd2DJYjT9eZ8iImFW9+CPqNP2L10Syl/WbuPf58xgtF900883xhjIpT9nD0dBzbAzrdh6jeCJgdfk597F21ieJ9Ubv/ssDAEaIwxnWcJ4nSs+A3EpcDkG4LufnrFbvZUHOWHXxxDQqxNAGSM6V4sQXRW9UH4cCFMvA6SMk/YXXXUx4P/2Mp5I7K5YGQ3nA7VGBP1LEF01gePgr8Jpn496O5fL9nGkfpGfnBJwRkOzBhjukaHEoSI/FlEviAillDAmddh1WNOP4feQ0/Yvcd7lCeX7+LqyQMp6GcV08aY7qmjX/i/Af4F2Coi94tIdE99tv45qKuEc24Puvvnr20hNiaGuy62SYCMMd1XhxKEqr6pql8BJgG7gDdF5D0RuUlE4kIZYMTx+53K6f4TYdA5J+xevbuSv314gFvPH0puemIYAjTGmK7R4SIjEckCbgRuBtYCD+AkjMUhiSxSbX0DvNvgnDtO6BCnqvzX3zbTJy2Bf7vgxKInY4zpTjrUUU5E/gKMAp4GvqSqB9xdz4vIqlAFF5GW/xrSB8CYy07Y9eqHB1mzp4qfXzWO5Hjrg2iM6d46+i32oKouDbZDVYu7MJ7IdmAD7HoHZt7nDOMdoKGpmZ+/toXRfdP48mQbytsY0/11tIhpjIhktKyISKaIfCNEMUWulo5xk07sGPf0cqdT3A8uKcATY0N5G2O6v44miFtUtaplRVUrgVtCE1KEOnLA6Rg36XpIymizq+qoj/9bso3zR+ZwvnWKM8b0EB1NEB4JmOFGRDxAfGhCilAr3Y5xZ//bCbv+b8k2qusb+cElJ47HZIwx3VVH6yBew6mQ/p27/m/utujgq4VVjwftGLfbW8tTy3dxdfFAG63VGNOjdDRBfA8nKdzmri8Gfh+SiCJRa8e4O07Y9cA/tuKJEe6aaZ3ijDE9S4cShKr6gYfdV3Tx+2HFw9B/Egya2mZXSeVRFq3bz/XnDKaPdYozxvQwHe0HMQL4GTAGaP0mVNWe3xts+xKnY9xVj53QMe7Rt3cgArec1/NvgzEm+nS0kvoJnKeHJuCzwFPAH0MVVERZ/6wznHfBpW02l9c0sGDlXi6fMID+GUlhCs4YY0KnowkiSVX/AYiq7lbV+cAXQhdWhKg/Alv+BmOvgti2jbae+OdOfM1+vj7dZoozxvRMHa2kbnCH+t4qIncA+4DU0IUVITa/DE31UHRtm83V9Y08tXw3swr7Miyn598GY0x06ugTxDeBZODfgcnAdUDweTZ7kvULIGs4DJjcZvMfV+yhur6Jb0wfHqbAjDEm9D71CcLtFDdHVf8DqAFuCnlUkaBqD+x+Fz57T5vK6frGZh57dyfnjchmXF6vMAZojDGh9alPEKraDJx7BmKJLBued97HX91m8wurSyivaeA2q3swxvRwHa2DWCsii4AXgNqWjar655OdJCKzcOaN8AC/V9X7j9v/K5xWUeAUYfVR1Qx3XzPwobtvj6q2bUYUSqqw/nkYfC5kDm7d3NTs55G3tzNhYAbnDM06Y+EYY0w4dDRBJAJe4MKAbQq0myDcoqmHgJlACbBSRBap6ubWC6jODTj+TmBiwCXqVHVCB+PrWvvWgHcrTPv3Nptf2XCAvRV1/PALYxCxEVuNMT1bR3tSd6beYQqwTVV3AIjIAuAyYHM7x18L3NuJz+l665+D2MQ2kwL5/crDy7YzMjeViwpywxicMcacGR3tSf0EzhNDG6r61ZOcNgDYG7BeApzdzvUHA0OAJQGbE93Z6pqA+1X1pSDn3QrcCjBo0KBP+Vd0UJMPNr4Ioy6BxGOV0Eu2lPLxoWp+NaeIGJvvwRgTBTpaxPRKwHIicAWwvwvjuAZY6FaItxisqvtEZCiwREQ+VNXtgSep6iPAIwDFxcUnJLBO2bYY6ira9H1QVR5ato28zCS+NL5/l3yMMcZEuo4WMb0YuC4izwHvfspp+4DAuTfz3G3BXAPcftxn7nPfd4jIMpz6ie0nntrF1j8HKTkw7Fh1y4odFazdU8VPLisk1tPRriPGGNO9dfbbbgTQ51OOWQmMEJEhIhKPkwQWHX+QiIwGMoHlAdsyRSTBXc4GptF+3UXXOVoBn7wO42aD51ju/M2ybWSnxjO72OaaNsZEj47WQVTTtg7iIM4cEe1S1SZ3WI7XcZq5Pq6qm0TkPmCVqrYki2uABaoaeP0C4Hci4sdJYvcHtn4KmU1/gWYfFF3TuumTQ9W8s7Wc784aRWKcJ+QhGGNMpOhoEVNaZy6uqq8Crx637UfHrc8Pct57wLjOfOZp2fA89BkDfce3bvrkUDUAM0ZbyyVjTHTpUBGTiFwhIr0C1jNE5PLQhRUG3u2w930YP6fN0BreGh8A2anRNQW3McZ0tA7iXlU93LKiqlVESp+FrrLheUBOGFrDW+tDBDKSLUEYY6JLRxNEsOM62kQ28qk6I7cOnQ7pbZuxemsa6J0cj8f6PhhjokxHE8QqEflfERnmvv4XWB3KwM6oPSuganebyukW3hofWVa8ZIyJQh1NEHcCPuB5YAFQz3H9Frq19c9BXAqM/uIJuypqfWSlJIQhKGOMCa+OtmKqBeaFOJbwaKyHTS/BmEsh4cTZ4cprGyjolx6GwIwxJrw62oppsYhkBKxnisjroQvrDKqrgPxpJ0wr2sJb4yM7xYqYjDHRp6MVzdluyyUAVLVSRD6tJ3X3kN4frn0u6K7GZj+H6xrJSrUiJmNM9OloHYRfRFqHSxWRfIKM7trTVNY6fSB62xOEMSYKdfQJ4m7gXRF5CxDgPNxhtnuycuskZ4yJYh2tpH5NRIpxksJa4CWgLpSBRQJvbQOAFTEZY6JSRwfruxn4Js6Q3euAqTijr154svO6uworYjLGRLGO1kF8EzgL2K2qn8WZm6Hq5Kd0f61FTNYPwhgThTqaIOpVtR5ARBJUdQswKnRhRQZvTQOxMUJ6Us8ZVcQYYzqqo998JW4/iJeAxSJSCewOXViRoWWYDREbh8kYE306Wkl9hbs4X0SWAr2A10IWVYTw1vrobcVLxpgodcplJ6r6VigCiUTe2gZr4mqMiVqdnZM6KnhrfGRZCyZjTJSyBHESFVbEZIyJYpYg2lHf2ExNQ5PNBWGMiVqWINrhrbVhNowx0c0SRDsqalp6UVsRkzEmOlmCaEd56zhM9gRhjIlOliDa4bVhNowxUc4SRDu8NfYEYYyJbpYg2lFR6yMhNobkeE+4QzHGmLCwBNGO8hof2akJNg6TMSZqWYJoh7e2wYqXjDFRzRJEO5xe1JYgjDHRyxJEO5xxmKwFkzEmelmCCEJVKa+xkVyNMdHNEkQQR33NNDT5rYjJGBPVLEEE0dJJLivVipiMMdHLEkQQNsyGMcZYggjKhtkwxhhLEEFVuE8Qve0JwhgTxUKaIERkloh8LCLbRGRekP2/EpF17usTEakK2HeDiGx1XzeEMs7jlbfUQVgltTEmisWG6sIi4gEeAmYCJcBKEVmkqptbjlHVuQHH3wlMdJd7A/cCxYACq91zK0MVbyBvjY/UhFgS42wcJmNM9ArlE8QUYByO0qsAABLzSURBVJuq7lBVH7AAuOwkx18LPOcufw5YrKoVblJYDMwKYaxtVNQ2WBNXY0zUC2WCGADsDVgvcbedQEQGA0OAJadyrojcKiKrRGRVWVlZlwQNznSj1oLJGBPtIqWS+hpgoao2n8pJqvqIqharanFOTk6XBVNuw2wYY0xIE8Q+YGDAep67LZhrOFa8dKrndrmK2garoDbGRL1QJoiVwAgRGSIi8ThJYNHxB4nIaCATWB6w+XXgYhHJFJFM4GJ3W8ipqjNQnxUxGWOiXMhaMalqk4jcgfPF7gEeV9VNInIfsEpVW5LFNcACVdWAcytE5Cc4SQbgPlWtCFWsgY7UNdHkVxtmwxgT9UKWIABU9VXg1eO2/ei49fntnPs48HjIgmtHyzAbNpKrMSbaRUoldcSoqHU6yVkzV2NMtLMEcRxvjTtQn7ViMsZEOUsQx2kZZsOKmIwx0c4SxHFaipgyrYjJGBPlLEEcx1vTQK+kOOI8dmuMMdHNvgWPU27DbBhjDGAJ4gQVNT7rRW2MMViCOIG3tsFaMBljDJYgTmDDbBhjjMMSRIBmv1Jx1GfDbBhjDJYg2qg66kPVpho1xhiwBNGG1+0DYUVMxhhjCaKNchtmwxhjWlmCCFBhTxDGGNPKEkQArzsOk9VBGGOMJYg2vDUNxAhkJFuCMMaYkE4Y1N14a31kJsfjiZFwh2JMxGtsbKSkpIT6+vpwh2I6IDExkby8POLi4jp8jiWIANZJzpiOKykpIS0tjfz8fETsR1UkU1W8Xi8lJSUMGTKkw+dZEVMAG2bDmI6rr68nKyvLkkM3ICJkZWWd8tOeJYgA9gRhzKmx5NB9dOa/lSWIAN5aG8nVGGNaWIJw+Zr8HK5rtHGYjDHGZQnCVXnUOskZ051UVVXxm9/85pTPu+SSS6iqqgpBRD2PtWJyWSc5Yzrvx3/dxOb9R7r0mmP6p3Pvlwrb3d+SIL7xjW+02d7U1ERsbPtfba+++mqXxRgKnxb/mWRPEC5vrTsOkxUxGdMtzJs3j+3btzNhwgTOOusszjvvPC699FLGjBkDwOWXX87kyZMpLCzkkUceaT0vPz+f8vJydu3aRUFBAbfccguFhYVcfPHF1NXVtft5jz76KGeddRZFRUVcddVVHD16FIBDhw5xxRVXUFRURFFREe+99x4ATz31FOPHj6eoqIjrr78egBtvvJGFCxe2XjM1NRWAZcuWdTj+1157jUmTJlFUVMSMGTPw+/2MGDGCsrIyAPx+P8OHD29dPy2q2iNekydP1tPxlzUlOvh7r+j20urTuo4x0WLz5s1h/fydO3dqYWGhqqouXbpUk5OTdceOHa37vV6vqqoePXpUCwsLtby8XFVVBw8erGVlZbpz5071eDy6du1aVVWdPXu2Pv300+1+Xsv5qqp33323Pvjgg6qqevXVV+uvfvUrVVVtamrSqqoq3bhxo44YMULLysraxHLDDTfoCy+80HqdlJSUU4q/tLRU8/LyWo9rOWb+/PmtMbz++ut65ZVXBv03BPtvBqzSdr5X7QnC1TrUt/WDMKZbmjJlSptOYA8++CBFRUVMnTqVvXv3snXr1hPOGTJkCBMmTABg8uTJ7Nq1q93rb9y4kfPOO49x48bxzDPPsGnTJgCWLFnCbbfdBoDH46FXr14sWbKE2bNnk52dDUDv3r27JP4VK1Zw/vnntx7Xct2vfvWrPPXUUwA8/vjj3HTTTZ/6eR0RGQVdEcBb00BsjJCeZLfEmO4oJSWldXnZsmW8+eabLF++nOTkZKZPnx60k1hCwrEfhB6P56RFTDfeeCMvvfQSRUVF/OEPf2DZsmWnHGNsbCx+vx9wioJ8Pt9pxd9i4MCB5ObmsmTJEj744AOeeeaZU44tGHuCcLV0krOOP8Z0D2lpaVRXVwfdd/jwYTIzM0lOTmbLli2sWLHitD+vurqafv360djY2OYLeMaMGTz88MMANDc3c/jwYS688EJeeOEFvF4vABUVFYBT/7F69WoAFi1aRGNj4ynFP3XqVN5++2127tzZ5roAN998M9dddx2zZ8/G4/Gc9r8XLEG0smE2jOlesrKymDZtGmPHjuU73/lOm32zZs2iqamJgoIC5s2bx9SpU0/7837yk59w9tlnM23aNEaPHt26/YEHHmDp0qWMGzeOyZMns3nzZgoLC7n77ru54IILKCoq4q677gLglltu4a233qKoqIjly5e3eWroSPw5OTk88sgjXHnllRQVFTFnzpzWcy699FJqamq6rHgJQJw6iu6vuLhYV61a1enzr/jNP0lNiOXpr53dhVEZ03N99NFHFBQUhDsM41q1ahVz587lnXfeafeYYP/NRGS1qhYHO94K3F3eGh+DeyeHOwxjjDll999/Pw8//HCX1T20sCIml7emwfpAGGO4/fbbmTBhQpvXE088Ee6wTmrevHns3r2bc889t0uva08QQH1jM7W+ZnpbL2pjot5DDz0U7hAihj1BcKwPRLaNw2SMMa1CmiBEZJaIfCwi20RkXjvHXC0im0Vkk4g8G7C9WUTWua9FoYzTW+MOs2GtmIwxplXIiphExAM8BMwESoCVIrJIVTcHHDMC+D4wTVUrRaRPwCXqVHVCqOIL1PIE0dueIIwxplUonyCmANtUdYeq+oAFwGXHHXML8JCqVgKoamkI42lXy0iu2fYEYYwxrUKZIAYAewPWS9xtgUYCI0XknyKyQkRmBexLFJFV7vbLQxjnsSIme4IwpsdqGTnVdFy4WzHFAiOA6UAe8LaIjFPVKmCwqu4TkaHAEhH5UFW3B54sIrcCtwIMGjSo00F4a30kxsWQHN813dONiTp/nwcHP+zaa/YdB5+/v2uvGQEiab6HTxPKJ4h9wMCA9Tx3W6ASYJGqNqrqTuATnISBqu5z33cAy4CJx3+Aqj6iqsWqWpyTk9PpQL01PrJSEmwcJmO6kXnz5rVpkjp//nz+8z//kxkzZjBp0iTGjRvHyy+/3KFr1dTUtHtesHkdgs0BsWvXLsaOHdt63i9/+Uvmz58PwPTp0/nWt75FcXExDzzwAH/96185++yzmThxIhdddBGHDh1qjeOmm25i3LhxjB8/nhdffJHHH3+cb33rW63XffTRR5k7d26n79spaW8c8NN94Twd7ACGAPHAeqDwuGNmAU+6y9k4RVJZQCaQELB9KzDmZJ93OvNB3PD4+/ql/3un0+cbE43CPR/EmjVr9Pzzz29dLygo0D179ujhw4dVVbWsrEyHDRumfr9fVY/NvRBMY2Nj0PPam9ch2BwQgfNTqKr+4he/0HvvvVdVVS+44AK97bbbWvdVVFS0xvXoo4/qXXfdpaqq3/3ud/Wb3/xmm+Oqq6t16NCh6vP5VFX1nHPO0Q0bNpzq7VLVU58PImTPOaraJCJ3AK8DHuBxVd0kIve5AS1y910sIpuBZuA7quoVkc8AvxMRP85Tzv0a0Pqpq3lrfNYHwphuZuLEiZSWlrJ//37KysrIzMykb9++zJ07l7fffpuYmBj27dvHoUOH6Nu370mvpar84Ac/OOG89uZ1WLJkSev8Cy1zQFRWVp70MwIH1ispKWHOnDkcOHAAn8/XOr/Dm2++yYIFC1qPy8zMBODCCy/klVdeoaCggMbGRsaNG3eKd6tzQloQpqqvAq8et+1HAcsK3OW+Ao95DzgzdwCoqPUxMjftTH2cMaaLzJ49m4ULF3Lw4EHmzJnDM888Q1lZGatXryYuLo78/PyTzqPQorPnBQqc6wE44fzAkVvvvPNO7rrrLi699FKWLVvWWhTVnptvvpmf/vSnjB49uktHa/00Ud+TWlUpr2mwJwhjuqE5c+awYMECFi5cyOzZszl8+DB9+vQhLi6OpUuXsnv37g5dp73z2pvXIdgcELm5uZSWluL1emloaOCVV1456ecNGOA06nzyySdbt8+cObNNvUrLU8nZZ5/N3r17efbZZ7n22ms7entOW9QniFpfMw1Nfmviakw3VFhYSHV1NQMGDKBfv3585StfYdWqVYwbN46nnnqqzbwNJ9Peee3N6xBsDoi4uDh+9KMfMWXKFGbOnHnSz54/fz6zZ89m8uTJrcVXAPfccw+VlZWMHTuWoqIili5d2rrv6quvZtq0aa3FTmdC1M8HUXXUxz0vbeTq4oGcP7LzLaGMiTY2H8SZ9cUvfpG5c+cyY8aMTl/jVOeDiPoniIzkeH79L5MsORhjIlJVVRUjR44kKSnptJJDZ3SP3hrGGNMFPvzww9a+DC0SEhJ4//33wxTRp8vIyOCTTz4Jy2dbgjDGdJqqdqsOpuPGjWPdunXhDiMsOlOdEPVFTMaYzklMTMTr9Xbqi8ecWaqK1+slMTHxlM6zJwhjTKfk5eVRUlJCWVlZuEMxHZCYmEheXt4pnWMJwhjTKXFxca09gE3PZEVMxhhjgrIEYYwxJihLEMYYY4LqMT2pRaQM6NjAK8FlA+VdFE5Xs9g6x2LrHIutc7prbINVNWhP4R6TIE6XiKxqr7t5uFlsnWOxdY7F1jk9MTYrYjLGGBOUJQhjjDFBWYI45pFwB3ASFlvnWGydY7F1To+LzeogjDHGBGVPEMYYY4KyBGGMMSaoqE8QIjJLRD4WkW0iMi/c8QQSkV0i8qGIrBORU58ur+vjeVxESkVkY8C23iKyWES2uu9nbj7Ek8c1X0T2ufdunYhccqbjcuMYKCJLRWSziGwSkW+62yPhvrUXW9jvnYgkisgHIrLeje3H7vYhIvK++/f6vIic8bmCTxLbH0RkZ8B9m3CmYwuI0SMia0XkFXe9c/dNVaP2BXiA7cBQIB5YD4wJd1wB8e0CssMdR0A85wOTgI0B2/4bmOcuzwN+HiFxzQf+IwLuWT9gkrucBnwCjImQ+9ZebGG/d4AAqe5yHPA+MBX4E3CNu/23wG0RFNsfgC+H+/85N667gGeBV9z1Tt23aH+CmAJsU9UdquoDFgCXhTmmiKWqbwMVx22+DHjSXX4SuPyMBkW7cUUEVT2gqmvc5WrgI2AAkXHf2ost7NRR467GuS8FLgQWutvDdd/aiy0iiEge8AXg9+660Mn7Fu0JYgCwN2C9hAj5A3Ep8IaIrBaRW8MdTDtyVfWAu3wQyA1nMMe5Q0Q2uEVQZ7wI53gikg9MxPnFGVH37bjYIALunVtMsg4oBRbjPO1XqWqTe0jY/l6Pj01VW+7bf7n37VcikhCO2ID/B3wX8LvrWXTyvkV7goh056rqJODzwO0icn64AzoZdZ5fI+WX1MPAMGACcAD4n3AGIyKpwIvAt1T1SOC+cN+3ILFFxL1T1WZVnQDk4Tztjw5HHMEcH5uIjAW+jxPjWUBv4HtnOi4R+SJQqqqru+J60Z4g9gEDA9bz3G0RQVX3ue+lwF9w/kgizSER6QfgvpeGOR4AVPWQ+0fsBx4ljPdOROJwvoCfUdU/u5sj4r4Fiy2S7p0bTxWwFDgHyBCRlonOwv73GhDbLLfITlW1AXiC8Ny3acClIrILp8j8QuABOnnfoj1BrARGuDX88cA1wKIwxwSAiKSISFrLMnAxsPHkZ4XFIuAGd/kG4OUwxtKq5cvXdQVhundu+e9jwEeq+r8Bu8J+39qLLRLunYjkiEiGu5wEzMSpI1kKfNk9LFz3LVhsWwISvuCU8Z/x+6aq31fVPFXNx/k+W6KqX6Gz9y3cte3hfgGX4LTe2A7cHe54AuIaitOqaj2wKRJiA57DKXJoxCnH/BpO+eY/gK3Am0DvCInraeBDYAPOl3G/MN2zc3GKjzYA69zXJRFy39qLLez3DhgPrHVj2Aj8yN0+FPgA2Aa8ACREUGxL3Pu2EfgjbkuncL2A6RxrxdSp+2ZDbRhjjAkq2ouYjDHGtMMShDHGmKAsQRhjjAnKEoQxxpigLEEYY4wJyhKEMRFARKa3jLxpTKSwBGGMMSYoSxDGnAIRuc6dC2CdiPzOHbStxh2cbZOI/ENEctxjJ4jICnfwtr+0DHonIsNF5E13PoE1IjLMvXyqiCwUkS0i8ozbI9eYsLEEYUwHiUgBMAeYps5Abc3AV4AUYJWqFgJvAfe6pzwFfE9Vx+P0sG3Z/gzwkKoWAZ/B6QUOzmiq38KZk2Eozrg6xoRN7KcfYoxxzQAmAyvdH/dJOIPs+YHn3WP+CPxZRHoBGar6lrv9SeAFd3ytAar6FwBVrQdwr/eBqpa46+uAfODd0P+zjAnOEoQxHSfAk6r6/TYbRX543HGdHb+mIWC5Gfv7NGFmRUzGdNw/gC+LSB9onVd6MM7fUctImf8CvKuqh4FKETnP3X498JY6M7eViMjl7jUSRCT5jP4rjOkg+4ViTAep6mYRuQdnlr8YnNFjbwdqcSaNuQenyGmOe8oNwG/dBLADuMndfj3wOxG5z73G7DP4zzCmw2w0V2NOk4jUqGpquOMwpqtZEZMxxpig7AnCGGNMUPYEYYwxJihLEMYYY4KyBGGMMSYoSxDGGGOCsgRhjDEmqP8PUHtHmZdz9IsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuuZmVdUtl9F",
        "outputId": "bac549c4-773c-4291-a60e-47d66982f4fa"
      },
      "source": [
        "#6. 검증 세트 정확도 계산하기\n",
        "loss, accuracy = model.evaluate(x_val, y_val_encoded, verbose=0)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8632500171661377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS0Y5-dCuQXP"
      },
      "source": [
        "#7. 테스트 세트 정확도 계산하기"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}